{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Scikit-learn, kNN, and Decision Trees\n",
    "\n",
    "\n",
    "In this lab we'll get some hands on experience with scikitlearn as well as two of the classifiers we've seen in class\n",
    "- K Nearest Neighbors\n",
    "- Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals for this lab\n",
    "\n",
    "- Get an overview of sklearn\n",
    "\n",
    "\n",
    "- Understand the practical implications for changing the parameters used in KNearest Neighbor Classifier\n",
    "  - k\n",
    "  - distance metric\n",
    "  - weighting method\n",
    "  \n",
    "  \n",
    "- Understand the practical implications for changing the parameters used in Decision Trees\n",
    " - splitting criteria (gini vs information gain)\n",
    " - max depth\n",
    " - min sample size for split\n",
    " \n",
    " \n",
    "- Understand how to interpret Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.tree as tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "import graphviz # If you don't have this, install via pip/conda\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "We'll use these classifiers on a subset of the data set from https://www.kaggle.com/new-york-state/nys-patient-characteristics-survey-pcs-2015\n",
    "\n",
    "The data has been downloaded, modified, and is in the github repo for the lab\n",
    "\n",
    "You should also try this with other data sets you have been provided for the homeworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to wherever you're storing your data\n",
    "datafile = '../data/nysmedicaldata.csv'\n",
    "df = pd.read_csv(dfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Quick Data Exploration\n",
    "Before running any sort of model on your dataset, it's always a good idea to do some quick data exploration to get a sense of how your data looks like. Try to answer the following questions with some sort of plot/histogram/etc:\n",
    "\n",
    "1) What do the distributions of each feature look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using scikitlearn for classification\n",
    "\n",
    "sklearn is a very useful python packager for building machiune learning models. To build a model in sklearn, you need to have a matrix (or dataframe) with X and y columns. X is your set of features/predictors. y is a single column that is your label. We'll take the foll;owing steps:\n",
    "\n",
    "1. Select/create column as label/outcome (y)\n",
    "2. Select/create columns as features (X)\n",
    "3. Create Training Set\n",
    "4. Create Validation Set\n",
    "5. Build model on Training Set\n",
    "6. Predict risk scores for the Validation Set\n",
    "7. Calculate performance metric(s)\n",
    "\n",
    "## Some useful things to know in sklearn\n",
    "\n",
    "fit = train an algorithm\n",
    "\n",
    "predict_proba = predict a \"risk\" score for all possible classes for a given record (classification only)\n",
    "\n",
    "\n",
    "## Important- never use .predict\n",
    "There is also a function called \"predict\" which first runs predict_probs and then predicts a 1 if the score > 0.5 and 0 otherwise. *Never* use that function since 0.5 is a completely arbitrary threshold to call a prediction 1 vs 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create label/outcome\n",
    "One thing we can do with this dataset is to try to use the various feature columns to classify whether a person has High Blood Pressure. Let's create a column that is 1 if a person has High Blood Pressure and 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: what percentage of people have High Blood Pressure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. create or select existing predictors/features\n",
    "\n",
    "For now, let's take a handful of existing columns to use.\n",
    "\n",
    "sklearn needs features to be numeric and not categorical so we'll have to turn our selected features to be binary (also known as dummy variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_transform = [ 'Sex', 'Race', 'Obesity', 'Smokes', 'Alcohol Related Disorder','Drug Substance Disorder',\n",
    "                    'Criminal Justice Status','Private Insurance']\n",
    "df = pd.get_dummies( df, dummy_na=True, columns = cols_to_transform )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['Sex_FEMALE','Sex_MALE','Sex_UNKNOWN','Race_BLACK ONLY','Race_MULTI-RACIAL','Race_OTHER',\n",
    "                     'Race_UNKNOWN RACE','Race_WHITE ONLY', 'Obesity_YES', 'Obesity_NO', 'Obesity_nan', \n",
    "                     'Smokes_YES', 'Smokes_NO','Alcohol Related Disorder_NO','Alcohol Related Disorder_YES',\n",
    "                    'Alcohol Related Disorder_UNKNOWN','Criminal Justice Status_YES','Criminal Justice Status_NO',\n",
    "                    'Criminal Justice Status_UNKNOWN','Private Insurance_NO','Private Insurance_YES','Private Insurance_UNKNOWN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Splits\n",
    "\n",
    "Create a train/test set split using sklearn's [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function. We'll use these train/test splits for evaluating all our classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[selected_features]\n",
    "y = df['HBP']\n",
    "test_size = 0.3 # you can adjust this\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# K Nearest Neighbors\n",
    "See the sklearn documentation on the [KNN classifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) to see its parameters. The one's we'll mostly be interested in are:\n",
    "- n_neighbors\n",
    "- distance metric\n",
    "- weighting function\n",
    "\n",
    "## KNN Distance Function\n",
    "Something important to note is that the KNN algorithm requires a \"metric\" or a notion of distance. If you don't set this parameter, it defaults to the Euclidean distance. Do you think the Euclidean distance is appropriate in this setting? You can set the metric parameter to any one of the distance metrics defined under the sklearn [DistanceMetric class](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html)\n",
    "\n",
    "Different metrics might have different parameters which you can set like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your metric has a metric parameter you need to pass that in via a\n",
    "# dictionary to metric_params.\n",
    "knn = KNeighborsClassifier(n_neighbors=10, metric='minkowski', metric_params={'p': 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that when training a model, **you should only use the training data!** The test set is reserved exclusively for evaluating your model. Now let's use the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(x_train, y_train)\n",
    "pred_scores = knn.predict_proba(x_test)[:1]\n",
    "plt.hist(pred_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Tasks:\n",
    "\n",
    "1) Write a function that computes the accuracy of the predicted values for a given score threshold\n",
    "If score > threshold then prediction = 1 else prediction = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Play around with the n_neighbors value. Fit your data on the training data(x_train, y_train). Then evaluate it on both the training data, and the testing data. How does the accuracy of your train and test set predictions change as you increase n_neighbors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) You can see what datapoints are closest to a given query point via the [kneighbors function](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.kneighbors). Which people are most closest to some of the highest scored people in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Use a different distance metric for the KNN classifier. Evaluate the train/test set accuracies with the new KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Use a different weighting function for the KNN classifier. Evaluate the train/test set accuracies with the new KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now write a nested for loop that loops over all the parameters and values and store the results in a data frame\n",
    "\n",
    "### pseudocode\n",
    "\n",
    "- for k in 1,2,3,4,5...10\n",
    "  - for distance metric in (metric1, metric2,...)\n",
    "    - for weighting function in (uniform, distance weighted)\n",
    "      - train model\n",
    "      - score test data\n",
    "      - evaluate - calculate metrics\n",
    "      - store parameters and evaluation metric in data frame\n",
    "- print dataframe\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise for later:\n",
    "You can now use this data frame to analyze the results and see how the model performs as you modify the parameters.\n",
    "How does the performance of knn change as you vary differenty parameters?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving onto decision trees. The [DecisionTreeClassifier constructor](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) can take a number of parameters. You should look at all the available \n",
    "- criterion: string, \"gini' for Gini Impurity or 'entropy' for information gain\n",
    "- splitter: string,  \"best\" or 'random'\n",
    "- max_features: the number of features to consider when looking for the best split.\n",
    "- max_depth: int, the maximum depth of the tree.\n",
    "- min_samples_split: minimum number of samples required to split an internal node\n",
    "- min_samples_leaf: min number of samples required to be at a leaf node.\n",
    "- max_leaf_nodes: max number of leaf nodes a tree can have\n",
    "\n",
    "We can do the same fit/predict_proba/calculate accuracy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's first fit a decision tree model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree = DecisionTreeClassifier()\n",
    "dec_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now predict scores on the test set and plot the distribution of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_scores_test = dec_tree.predict_proba(x_test)[:,1]\n",
    "plt.hist(predicted_scores_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we can select a threshold and calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.4\n",
    "calc_threshold = lambda x,y: 0 if x < y else 1 \n",
    "predicted_test = np.array( [calc_threshold(score, threshold) for score in predicted_scores_test] )\n",
    "test_acc = accuracy(predicted_test, y_test)\n",
    "print test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's now explore how the performance changes as we change parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be interested in how each of these parameters will affect the performance of a Decision Tree classifier.\n",
    "\n",
    "For example: Increasing max_depth this should increase your model's ability to explain the data and eventually overfit the training data once it's high enough. The performance on the test set should degrade a bit as the training set is overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.4\n",
    "depths = [1, 3, 5, 7, 9, 20, 50, 100]\n",
    "for d in depths:\n",
    "    dec_tree = DecisionTreeClassifier(max_depth=d)\n",
    "    dec_tree.fit(x_train, y_train)\n",
    "\n",
    "    train_scores = dec_tree.predict_proba(x_train)[:,1]\n",
    "    test_scores = dec_tree.predict_proba(x_test)[:,1]\n",
    "   \n",
    "    predicted_train = np.array( [calc_threshold(score, threshold) for score in train_scores] )\n",
    "    train_acc = accuracy(predicted_train, y_train)   \n",
    "\n",
    "    predicted_test = np.array( [calc_threshold(score, threshold) for score in test_scores] )\n",
    "    test_acc = accuracy(predicted_test, y_test)\n",
    "    \n",
    "    print(\"Depth: {} | Train acc: {:.2f} | Test acc: {:.2f}\".format(d, train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Tasks\n",
    "1) Repeat the above with each parameter in DecisionTreeClassifier. What range of values makes sense for each parameter?\n",
    "(IE: does it make sense to have max_depth greater than 7 or 8 for this dataset?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) What do you think will happen if you normalize/scale one of the features of your dataset before passing it into the DecisionTreeClassifier.fit function? Try modifying one of your columns and rerun the evaluations above.\n",
    "Do the results change? Why does/doesnt this change the resulting model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) How does changing the \"criterion\" parameter affect your model. Is Gini better than Information Gain? Do not change the other parameters(max_depth, min_sample_split, etc) while doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Decision Trees are widely used in practice because they're very interpretable. Check out the [feature_importances](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.feature_importances_) attribute of the DecisionTreeClassifier. What features are the most informative according to this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing a Decision Tree\n",
    "We can visualize decision trees by exporting the model in graphviz format using the [sklearn.tree.export_graphviz function](http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html). This can be very useful in diagnosing potential issues with your Decision Tree Classifier giving you poor results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viz = tree.export_graphviz(dec_tree, feature_names=x_train.columns,\n",
    "                           class_names=['Europe', 'Not Europe'],\n",
    "                           rounded=True, filled=True)\n",
    "\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "    graph = graphviz.Source(dot_graph)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Visualize the decision tree of your best performing decision tree. Is there anything surprising about the splits that are most informative of this classification task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise for later:\n",
    "Now write a nested for loop that loops over all the parameters and values and store the results in a data frame.\n",
    "You can now use this data frame to analyze the results and see how the model performs as you modify the parameters.\n",
    "How does the performance of decision tree change as you vary differenty parameters?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "http://scikit-learn.org/stable/modules/neighbors.html#classification\n",
    "    \n",
    "http://scikit-learn.org/stable/modules/tree.html#tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
